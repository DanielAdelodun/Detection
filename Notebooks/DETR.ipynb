{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import shlex\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123.675, 116.28 , 103.53 ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.485, 0.456, 0.406]) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [\n",
    "    [125,  46, 141],\n",
    "    [118, 171,  47],\n",
    "    [ 76, 189, 237]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize(800),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "# def plot_results(pil_img, prob, boxes):\n",
    "#     plt.figure(figsize=(16,10))\n",
    "#     plt.imshow(pil_img)\n",
    "#     ax = plt.gca()\n",
    "#     colors = COLORS * 100\n",
    "#     for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "#         ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "#                                    fill=False, color=c, linewidth=3))\n",
    "#         cl = p.argmax()\n",
    "#         text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "#         ax.text(xmin, ymin, text, fontsize=15,\n",
    "#                 bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recGabriel = \"ffmpeg -nostdin -probesize 32 -flags low_delay -fflags nobuffer -codec:v h264_cuvid -r 25 -i tcp://gabriel.local:5001 -pix_fmt rgb24 -an -vcodec rawvideo -f rawvideo pipe:\"\n",
    "recGabriel = shlex.split(recGabriel)\n",
    "process = subprocess.Popen(recGabriel, stdout=subprocess.PIPE)\n",
    "\n",
    "width = 1280\n",
    "height = 1280\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraBufferCleanerThread(threading.Thread):\n",
    "    def __init__(self, camera_process, name='camera-buffer-cleaner-thread'):\n",
    "        self.camera = camera_process\n",
    "        self.last_frame = None\n",
    "        super(CameraBufferCleanerThread, self).__init__(name=name)\n",
    "        self.start()\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            raw_frame = self.camera.stdout.read(width*height*3)\n",
    "\n",
    "            if len(raw_frame) != (width*height*3):\n",
    "                print('Error reading frame!!!')\n",
    "\n",
    "            else:\n",
    "                # Transform the byte read into a numpy array, and reshape it to video frame dimensions\n",
    "                frame = np.frombuffer(raw_frame, np.uint8)\n",
    "                self.last_frame = frame.reshape((height, width, 3))\n",
    "\n",
    "CameraCleaner = CameraBufferCleanerThread(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "\n",
    "    # Flush the stdout to avoid buffering problems\n",
    "    frame = CameraCleaner.last_frame\n",
    "\n",
    "    # mean-std normalize the input image (batch-size: 1)\n",
    "    batch = transform(frame).unsqueeze(0)\n",
    "\n",
    "    # propagate through the model\n",
    "    outputs = model(batch)\n",
    "\n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > 0.7\n",
    "\n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], frame.shape[:2])\n",
    "\n",
    "    # Convert Image to OpenCV\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    colors = COLORS * 100\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(probas[keep], bboxes_scaled.tolist(), colors):\n",
    "\n",
    "        label = f'{CLASSES[p.argmax()]}: {p[p.argmax()]:0.2f}'\n",
    "\n",
    "        cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax), int(ymax)), c, 2)\n",
    "        cv2.putText(frame, label, (int(xmin), int(ymin)), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = CameraCleaner.last_frame\n",
    "\n",
    "transform(frame)[1][400][300:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
